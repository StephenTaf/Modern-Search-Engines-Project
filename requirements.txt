# ------------- core scientific stack (CPU/GPU compatible) -------------
numpy>=1.26,<2.0
scikit-learn==1.7.0

# ------------- dense-retrieval stack -----------------------------------
sentence-transformers>=2.6.0   # pulls HuggingFace + TorchText deps

# choose ONE of the two lines below
faiss-gpu-cu12==1.11.0         # GPU build, needs CUDA 12.x
# faiss-cpu==1.7.4             # ← uncomment if you’re on CPU only

# ------------- PyTorch with CUDA 12.1 (optional, matches faiss build) ---
# pick the wheel that matches your GPU / driver.  Example:
#torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

requests[socks]>=2.31.0    # HTTP requests with SOCKS proxy support
urllib3>=1.26.0            # Low-level HTTP client (used by requests)

duckdb>=0.9.0             # Embedded analytical database for URL storage

heapdict>=1.0.1           # Priority queue for frontier management

beautifulsoup4>=4.12.0    # HTML/XML parsing and extraction
lxml>=4.9.0               # Fast XML/HTML parser backend for BeautifulSoup

langdetect>=1.0.9         # Language detection for extracted text

cloudscraper>=1.2.71      # Cloudflare protection bypass

brotli>=1.1.0             # Brotli compression support for modern websites

fastapi>=0.104.0          # FastAPI web framework
uvicorn>=0.24.0           # ASGI server for FastAPI
openai>=1.3.0             # OpenAI API client
pyyaml>=6.0.1             # YAML configuration file parsing
cerebras-cloud-sdk>=0.4.0  # Cerebras Cloud SDK for LLM inference

pytest>=7.4.0            # Testing framework
pytest-cov>=4.1.0        # Coverage reporting for tests
