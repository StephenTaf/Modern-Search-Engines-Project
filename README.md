# ğŸ” TÃ¼bingen Search Engine

A modern semantic search engine focused on English-language content related to TÃ¼bingen, built with dense embeddings, vector search, and interactive visualization.

## ğŸŒŸ Project Overview

This project implements a complete search engine pipeline that crawls, indexes, and searches English-language content about TÃ¼bingen using state-of-the-art semantic search techniques.

### Key Features

- **ğŸ•·ï¸ Web Crawling**: Focused crawling of TÃ¼bingen-related English content
- **ğŸ§  Semantic Search**: Dense vector embeddings using Sentence Transformers
- **âš¡ Vector Database**: DuckDB with native vector search and HNSW indexing
- **ğŸ¯ API-based Reranking**: OpenAI embedding API for fine-grained relevance scoring
- **ğŸ¨ Interactive UI**: D3.js-powered bubble visualization interface
- **ğŸš€ RESTful API**: Flask-based search API with CORS support

## ğŸ—ï¸ Architecture Overview

### Indexing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Crawler   â”‚â”€â”€â”€â–¶â”‚   DuckDB Store   â”‚â”€â”€â”€â–¶â”‚   Text Chunker  â”‚
â”‚                 â”‚    â”‚   (urlsDB)       â”‚    â”‚  (Sliding Win.) â”‚
â”‚ â€¢ Seed URLs     â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ Domain Focus  â”‚    â”‚ â€¢ URL + Metadata â”‚    â”‚ â€¢ 256 tokens    â”‚
â”‚ â€¢ Quality Score â”‚    â”‚ â€¢ Page Content   â”‚    â”‚ â€¢ 64 step size  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Vector Index  â”‚â—€â”€â”€â”€â”‚   Text Embedder  â”‚â—€â”€â”€â”€â”‚  Chunk Storage  â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ DuckDB HNSW   â”‚    â”‚ â€¢ SentenceTransf â”‚    â”‚ â€¢ chunks_optim. â”‚
â”‚ â€¢ Vector Search â”‚    â”‚ â€¢ MiniLM-L6-v2   â”‚    â”‚ â€¢ embeddings    â”‚
â”‚ â€¢ Inner Product â”‚    â”‚ â€¢ 384 dimensions â”‚    â”‚ â€¢ chunk_id map  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Query Processing Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Search Query   â”‚â”€â”€â”€â–¶â”‚  Query Embedding â”‚â”€â”€â”€â–¶â”‚  Vector Search  â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ User Input    â”‚    â”‚ â€¢ Same Model     â”‚    â”‚ â€¢ DuckDB HNSW   â”‚
â”‚ â€¢ Text String   â”‚    â”‚ â€¢ 384-dim vector â”‚    â”‚ â€¢ Top-K chunks  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Search Results  â”‚â—€â”€â”€â”€â”‚   API Reranker   â”‚â—€â”€â”€â”€â”‚ Result Assembly â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ Ranked Docs   â”‚    â”‚ â€¢ OpenAI Embed.  â”‚    â”‚ â€¢ Join Metadata â”‚
â”‚ â€¢ Similarity    â”‚    â”‚ â€¢ Sliding Window â”‚    â”‚ â€¢ Score Aggr.   â”‚
â”‚ â€¢ Metadata      â”‚    â”‚ â€¢ Fine-grained   â”‚    â”‚ â€¢ Deduplication â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technology Stack

### Core Components
- **Vector Database**: DuckDB with native vector search capabilities
- **Vector Indexing**: HNSW (Hierarchical Navigable Small Worlds) algorithm  
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2)
- **Web Framework**: Flask with CORS support
- **Frontend**: Vanilla JavaScript + D3.js

### Dependencies
- `sentence-transformers>=5.0.0` - Dense text embeddings
- `duckdb==1.3.1` - Analytical database with vector search support
- `flask>=2.3.0` - Web API framework
- `openai` - API client for reranking embeddings
- `numpy>=2.3.1` - Numerical computations
- `scikit-learn==1.7.0` - ML utilities


## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone the repository
git clone <repository-url>
cd Modern-Search-Engines-Project

# Install dependencies
pip install -r requirements.txt
```

### 2. Run the Search Engine

#### Option A: Command Line Interface
```bash
python main.py
```

#### Option B: Web API + Interactive UI
```bash
python search_api.py
```
Then open `http://localhost:5000` in your browser.

### 3. Usage Examples

**Command Line:**
```bash
>> university research tÃ¼bingen
>> historical old town
>> neckar river activities
```

**API Request:**
```bash
curl -X POST http://localhost:5000/api/search \
  -H "Content-Type: application/json" \
  -d '{"query": "university research", "top_k": 10}'
```

## ğŸ“ Project Structure

### Core Search Engine
```
â”œâ”€â”€ main.py                 # CLI search interface
â”œâ”€â”€ search_api.py           # Flask web API  
â”œâ”€â”€ retriever.py            # Main search logic
â”œâ”€â”€ config.py               # Configuration settings
â””â”€â”€ requirements.txt        # Python dependencies
```

### Indexing System
```
indexer/
â”œâ”€â”€ indexer.py              # Document indexing orchestrator
â”œâ”€â”€ embedder.py             # Text embedding & vector storage
â””â”€â”€ bm25.py                 # BM25 scoring (optional)
```

### Web Interface
```
templates/
â””â”€â”€ index.html              # Search interface with D3.js
static/
â”œâ”€â”€ style.css               # UI styling
â””â”€â”€ main.js                 # Interactive visualization
```

### Crawling Infrastructure
```
MaxPart/crawler/
â”œâ”€â”€ seed.py                 # Seed URL definitions
â”œâ”€â”€ metric.py               # Page quality scoring
â”œâ”€â”€ UTEMA.py               # Main crawler logic
â””â”€â”€ CrawlerHelpers.py       # Utility functions
```

### Optional Reranker
```
reranker/
â”œâ”€â”€ reranker_api.py         # API-based reranking service
â”œâ”€â”€ config.yaml             # Reranker configuration
â””â”€â”€ README.md               # Detailed reranker docs
```

### Research Components (Demos)
```
query_processing/           # Alternative ranking models
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ bm25.py            # BM25 implementation
â”‚   â”œâ”€â”€ tfidf.py           # TF-IDF scoring
â”‚   â”œâ”€â”€ bi_encoder.py      # Dense retrieval
â”‚   â””â”€â”€ pointwise_ltr.py   # Learning-to-rank
â””â”€â”€ demo_*.py              # Model demonstrations
```

## âš™ï¸ Configuration

Key settings in `config.py`:

```python
# Embedding Configuration
EMBEDDING_MODEL = "all-MiniLM-L6-v2"    # Sentence transformer model
EMBEDDING_DIMENSION = 384                # Vector dimension

# Database Settings  
DB_PATH = "index/crawlerDB.duckdb"       # Main database location
DB_TABLE = "urlsDB"                      # Document table name

# Processing Parameters
DEFAULT_BATCH_SIZE = 32                  # Document processing batch
DEFAULT_EMBEDDING_BATCH_SIZE = 64        # Embedding batch size
DEFAULT_WINDOW_SIZE = 256                # Text chunk size (tokens)
DEFAULT_STEP_SIZE = 64                   # Sliding window step

# Search Settings
MAX_CANDIDATES = 1000                    # Vector search candidates
USE_BM25 = False                         # Enable BM25 fallback
```

## ğŸ¯ Search Process Details

### 1. Document Indexing
1. **Text Chunking**: Documents split into overlapping 256-token windows
2. **Embedding Generation**: Each chunk encoded to 384-dimensional vectors  
3. **Vector Storage**: Embeddings stored in DuckDB with HNSW indexing
4. **Metadata Linking**: Chunks linked to source documents and URLs

### 2. Query Processing
1. **Query Embedding**: User query encoded with same transformer model
2. **Vector Search**: DuckDB HNSW index finds most similar document chunks
3. **Score Aggregation**: Chunk scores aggregated by document
4. **Result Ranking**: Documents ranked by maximum chunk similarity
5. **Metadata Enrichment**: Results enhanced with titles, URLs, snippets

### 3. API-based Reranking
1. **Candidate Selection**: Top-K documents from initial search
2. **Fine-grained Analysis**: Sliding window reanalysis of full documents  
3. **API Embeddings**: OpenAI embedding API for enhanced similarity computation
4. **Final Ranking**: Improved relevance ordering based on API embeddings

## ğŸ¨ Interactive Features

### Bubble Visualization
- **Dynamic Sizing**: Bubble size reflects relevance score
- **Color Coding**: Different colors for various content domains
- **Interactive**: Click bubbles to view full document details
- **Real-time**: Updates dynamically with new searches

### Search Interface
- **Autocomplete**: Smart query suggestions
- **Real-time Results**: Instant search as you type
- **Faceted Navigation**: Filter by content type, domain, date
- **Export Options**: Download results in various formats

## ğŸ“Š Performance Characteristics

### Search Speed
- **Cold Start**: ~2-3 seconds (first query after startup)
- **Warm Queries**: ~100-500ms (cached embeddings)
- **Batch Processing**: 10-100x faster with optimized batching

### Accuracy Metrics
- **Semantic Understanding**: Handles synonyms and context
- **Multilingual Robustness**: Works with mixed German/English content
- **Domain Specificity**: Optimized for TÃ¼bingen-related queries

### Scalability
- **Document Capacity**: Efficiently handles 10K+ documents
- **Memory Usage**: ~2GB RAM for full index in memory
- **GPU Acceleration**: Optional CUDA support for larger datasets

## ğŸ”§ Advanced Usage

### Custom Embedding Models
```python
# In config.py, change the model:
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
```

### Batch Processing
```python
# Process multiple documents efficiently
indexer_instance.index_documents(
    batch_size=64,
    embedding_batch_size=128,
    force_reindex=False
)
```

### API Integration
```python
import requests

response = requests.post('http://localhost:5000/api/search', json={
    'query': 'machine learning research',
    'top_k': 5,
    'include_snippets': True
})
results = response.json()
```
