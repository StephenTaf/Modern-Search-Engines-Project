# Document Reranker API Configuration

# OpenAI API Configuration
openai:
  api_key: "" # Set your API key
  embedding_model: "BAAI/bge-large-en-v1.5"  # OpenAI embedding model to use
  batch_size: 100  # Number of texts to process in parallel. Now uses true batching - fewer API calls!
  base_url: "https://api.together.xyz/v1"

# HuggingFace Model Configuration
huggingface:
  model_name: "BAAI/bge-large-en-v1.5"  # HuggingFace tokenizer model
  # Alternative options:
  # model_name: "BAAI/bge-base-en-v1.5"
  # model_name: "intfloat/multilingual-e5-large-instruct"
  # model_name: "Alibaba-NLP/gte-modernbert-base"

# Default Parameters for Sliding Windows
sliding_window:
  default_window_size: 500  # Default number of tokens per window
  default_step_size: 400    # Default step size for sliding windows
  default_top_n: 20         # Default number of top windows to return

# Server Configuration
server:
  host: "0.0.0.0"     # Server host (0.0.0.0 for all interfaces, 127.0.0.1 for localhost only)
  port: 8000          # Server port
  title: "Document Reranker API"
  version: "1.0.0"
  description: "A FastAPI-based web service that reranks text documents based on semantic similarity to a query using sliding window embeddings"

# File Processing Configuration
file_processing:
  supported_extensions: [".txt"]  # Supported file extensions
  encoding: "utf-8"              # File encoding
  max_file_size_mb: 100          # Maximum file size in MB (optional limit)

# Database Configuration
database:
  data_path: "index/crawlerDB.duckdb"
  # JSON file should contain list of dicts with fields: doc_id, sentence, title, url, text, similarity

# Similarity Calculation
similarity:
  metric: "cosine"  # Similarity metric (cosine, euclidean, etc.)
  
# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Performance Settings
performance:
  max_concurrent_files: 10    # Maximum number of files to process concurrently
  timeout_seconds: 300        # Request timeout in seconds
  memory_limit_mb: 2048       # Memory limit in MB (optional)

# API Rate Limiting (optional)
rate_limiting:
  enabled: true               # Enable/disable rate limiting
  requests_per_minute: 2400   # Max API requests per minute (with batching, actual requests are much fewer)
  
# Cache Settings (for future implementation)
cache:
  enabled: false              # Enable/disable caching
  ttl_seconds: 3600          # Cache time-to-live in seconds
  max_size_mb: 500           # Maximum cache size in MB 
