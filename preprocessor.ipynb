{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3480ed51",
   "metadata": {},
   "source": [
    "This notebook is used to merge crawled data from different sources, preprocess them and write to to DB before indexing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cb1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install polyglot\n",
    "# !pip install polyglot\n",
    "# !pip install PyICU\n",
    "# !pip install pycld2\n",
    "# !pip install langdetect\n",
    "# !pip install swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb34556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import swifter\n",
    "from langdetect import detect\n",
    "from polyglot.detect import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05346484",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_existing = duckdb.connect('crawlerDb.duckdb')\n",
    "conn_new = duckdb.connect('crawler_v4.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_existing = conn_existing.execute(\"select * from urlsDB\").df()\n",
    "df_new = conn_new.execute(\"select * from urlsDB\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72489df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to filter out duplicate URLs\n",
    "def normalise_url(url):\n",
    "    if url.startswith(\"https://\"):\n",
    "        return url[8:]\n",
    "    elif url.startswith(\"http://\"):\n",
    "        return url[7:]\n",
    "    # remove query parameters\n",
    "    if '?' in url:\n",
    "        url = url.split('?')[0]\n",
    "    # remove trailing slashes\n",
    "    if url.endswith('/'):\n",
    "        url = url[:-1]\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5551b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_existing['normalised_url'] = df_existing['url'].swifter.apply(normalise_url)\n",
    "df_new['normalised_url'] = df_new['url'].swifter.apply(normalise_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "print(f'len(df_new): {len(df_new)}')\n",
    "df_new = df_new[~df_new['normalised_url'].isin(df_existing['normalised_url'])]\n",
    "print(f'len(df_new) after removing existing: {len(df_new)}')\n",
    "# remove duplicates within df_new\n",
    "df_new = df_new.drop_duplicates(subset=['normalised_url'])\n",
    "print(f'len(df_new) after removing duplicates: {len(df_new)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8be3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.drop(columns=['normalised_url'], inplace=True)\n",
    "df_existing.drop(columns=['normalised_url'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d8b55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9ee0a59",
   "metadata": {},
   "source": [
    "## Language Deetection:\n",
    "Detecting if a text is in English isn't quite easy. Some of the existing python packages struggle with either very short or long texts. To be lenient, we try detetcting the english language from libraries langdetect and polygot. If either of them says the language of the text is english with a confidence of atleast 15% we accept, else we reject it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d52800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_english_langdetect(text):\n",
    "    if len(text) > 2:\n",
    "        try:\n",
    "            return detect(text) == 'en'\n",
    "        except:\n",
    "            print(f\"Error detecting language for text: {text[:100]}...\")  \n",
    "            return False\n",
    "    return False\n",
    "\n",
    "def is_english_polyglot(text):\n",
    "    try:\n",
    "        detector = Detector(text)\n",
    "        for language in detector.languages:\n",
    "            if language.code == 'en' and language.confidence > 0.15:\n",
    "                return True\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting language for text: {text[:100]}... Error: {e}\") \n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['is_english_langdetect'] = df_new['text'].swifter.apply(is_english_langdetect)\n",
    "df_new['is_english_polyglot'] = df_new['text'].swifter.apply(is_english_polyglot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1164e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.is_english_langdetect.value_counts(), df_new.is_english_polyglot.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_english = df_new[(df_new.is_english_langdetect == True) | (df_new.is_english_polyglot == True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = df_new_english.drop(columns=['is_english_langdetect', 'is_english_polyglot'])\n",
    "df_english = df_english.drop_duplicates(subset=['url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = df_existing['id'].max()\n",
    "df_english['id'] = range(max_id + 1, max_id + 1 + len(df_english))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change lastFetch to unix timestamp\n",
    "df_english['lastFetch'] = pd.to_datetime(df_english['lastFetch']).astype('int64') \n",
    "# rename columns\n",
    "df_english = df_english.rename(columns={\n",
    "    'parentUrl': 'incoming',\n",
    "}, inplace=True)\n",
    "# remove columns that are not in df_existing\n",
    "df_english = df_english[df_existing.columns]\n",
    "df_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92178c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([df_existing, df_english], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2369cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the old table and create a new one\n",
    "conn_existing.execute(\"DROP TABLE IF EXISTS urlsDB\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e681aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_existing.execute(\"CREATE TABLE urlsDB AS SELECT * FROM concat_df\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52618e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_existing.close()\n",
    "conn_new.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d4351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
